{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome, In this workshop you will learn how to build convolutional neural networks using Pytorch.\n",
    "\n",
    "\n",
    "You've already learned how to create a neural networks with pytorch, after mastering the basics of AI you will have the chance to dig deeper in the subject with convolutions and probabilistic prediction.\n",
    "\n",
    "Fully connected neural networks aren't the answer to every problem. Some probleme like object detection have low success rate when using fully connected neural networks, most object detection AI uses convolutional neural networks to solve this problem.\n",
    "\n",
    "In this exercise you will learn what are convolutional neural networks and how to create them. The end goal of the workshop is to create a AI to identify numbers.\n",
    "\n",
    "\n",
    "The first step will be to install and import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data for the AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before actually learning about convolution, let's start by creating a fully connected neural network to identify numbers.\\\n",
    "This will be useful to compare the efficiency of both AI.\n",
    "\n",
    "\n",
    "Let's start by downloading our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "  root=\"./data/MNIST\",\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "  ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "  root=\"./data/MNIST\",\n",
    "  train=False,\n",
    "  download=True,\n",
    "  transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "  ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(train_set[i][0].reshape(28, 28, 1), cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_set[0]\n",
    "print(\"total images :\", len(train_set)) # pixels value\n",
    "print(\"shape :\", image.shape) # pixels value\n",
    "print(\"label :\", label) # Number represented in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have images 28 pixels high and 28 pixels wide, with one channel. A colored has 3 channel for each primary color (RGB: Red, Green, and Blue).\n",
    "\n",
    "These images represent a number from 0 to 9, we have 10 different labels (or 10 different possible output). The first picture represent a 5, thus its label is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60000 is a lot of images to process one by one, to make it easier to process this data by our model while training we are going to use `batch`\n",
    "\n",
    "`Batch` is a hyperparameter that defines the number of samples to work through before updating the internal model parameters. In other words, before calculating the error and apply backpropagation after each image, if our batch size is 64 we will go through 64 images before doing it. This improves the learning rate of our AI by applying the backpropagation on the error average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
    "\n",
    "print(\"nuber of batches :\", len(train_loader))\n",
    "\n",
    "batch = next(iter(train_loader)) #take the first batch\n",
    "images, labels = batch\n",
    "print(\"shape :\", images.shape)\n",
    "print(\"labels :\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 938 'blocks' containing 64 image each (and their equivalent labels). This will drasticlly decrease our training time because with one pass, 64 images are processed.\n",
    "\n",
    "Pytorch is built to be used with batch, it is thus quite simple to implement it in our code.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(1, 10)\n",
    "        self.linear2 = torch.nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.nn.functional.relu(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "model = MyNetwork()\n",
    "input = torch.ones((64, 1), dtype=torch.float)\n",
    "\n",
    "mse = torch.nn.MSELoss() # Loss function\n",
    "expected = torch.ones((64, 1), dtype=torch.float)\n",
    "\n",
    "output = model.forward(input)\n",
    "loss = mse(output, expected)\n",
    "\n",
    "print(\"Input  :\", input.shape)\n",
    "print(\"Output :\", output.shape)\n",
    "print(\"loss :\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model accepts and return the data and prediction in batch. This also applies in every loss function, we can pass the batch of the predictions and the batch of expected values. The final loss will be the average of each loss in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference is going to be the output of our model. In this exercise, we are using a probabilistic approach. This means that are model will output a \"probality\" for each labels. We have 10 labels, our model should output 10 values. The label with the highest value will be the label predicted by the model.\n",
    "\n",
    "The mean squared error isn't meant to deal with this type of output. To calculate the loss we are gonna need the cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fonct = torch.nn.CrossEntropyLoss() # Loss function\n",
    "\n",
    "output = torch.rand((64, 10), dtype=torch.float) # theoretical output of the model\n",
    "expected = torch.ones((64), dtype=torch.long) # expected labels\n",
    "\n",
    "loss_fonct(output, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss takes the output of the model and the expected label. You don't need to calculate the label of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with Probabilistic Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise :**\\\n",
    "With all this information, it's your turn to build a simple model (without convolution) to identify the number in the given images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # code\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # code\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 2\n",
    "\n",
    "model = MyModel()\n",
    "loss_fonct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(EPOCH): #training\n",
    "    for batch in train_loader:\n",
    "        # code\n",
    "        pass\n",
    "\n",
    "\n",
    "total, correct = 0, 0\n",
    "for image, label in test_set: #testing\n",
    "    output = model.forward(image.reshape(1, 28 * 28))\n",
    "    if (output.argmax(dim=1).item() == label):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "print(\"Accuracy:\", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected :**\\\n",
    "`An accuracy above 75% is acceptable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we built a fully connected model to identify numbers in images. We will try to do the same but with a convolution model.\n",
    "\n",
    "Convolution can be discribe by taken a filter (kernel) and applying it to a given image, this might not make sense but let me illustrate it:\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src=\"./.img/conv.gif\" width=\"600\" style=\"padding-left: 20px;\"/>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "In this exemple we have our image (5 x 5), and a filter (3 x 3).\n",
    "We take the first (3 x 3) square in our image, and multiply it by our filter:\\\n",
    "`7 * 1 + 2 * 0 + 3 * -1 +`\\\n",
    "`4 * 1 + 5 * 0 + 3 * -1 +`\\\n",
    "`3 * 1 + 3 * 0 + 2 * -1 = 6`\\\n",
    "After that we move to the right by 1 column, and repeat. Once we arrive to the far right, we go down one row and start from the left.\n",
    "\n",
    "This is what happens when a image is passed through a convolution layer.\n",
    "Here are concrete examples:\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src=\"./.img/conv_exemple.png\" width=\"600\" style=\"padding-left: 20px;\"/>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "In a fully connected network, the weights and bias are changed to improve the prediction. In convolutional network, the filter are changed in each backward pass.\n",
    "\n",
    "Each convolution layer has its own filter, with multiple parameters such as:\\\n",
    "`Kernel size:` size of the filter(kernel)\\\n",
    "`stride:`the amount of column / row we move to the right / bottom\\\n",
    "`padding:` column / row of zeros added to the edge of the image\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src=\"./.img/params_exemple.png\" width=\"600\" style=\"padding-left: 20px;\"/>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "The shape of th eoutput can be calculated with the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN output size formula (square)\n",
    "- we have an $n * n$ input\n",
    "- we have an $f * f$ filter\n",
    "- we have a padding $p$\n",
    "- we have a filter $f$\n",
    "- we have an output size $O$\n",
    "\n",
    "## $O = \\frac{n - f +2p}{s} + 1$\n",
    "\n",
    "## CNN output size formula (non square)\n",
    "- we have an $Nh * Nw$ input\n",
    "- we have an $Fh * Fw$ filter\n",
    "- we have a padding $p$\n",
    "- we have a filter $f$\n",
    "- we have an output size $O$\n",
    "\n",
    "## $Oh = \\frac{Nh - Fh +2p}{s} + 1$\n",
    "## $Ow = \\frac{Nw - Fw +2p}{s} + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know have convolutions work, let's try to use them\n",
    "\n",
    "**Exercise :**\\\n",
    "By changing the convolution parameters, try to match the expected output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(1, 1, 28, 28)\n",
    "filter = torch.randn(1, 1, 3, 3)\n",
    "\n",
    "out_feat_F = F.conv2d()# code\n",
    "out_feat_F.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected :** `torch.Size([1, 1, 26, 26])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(1, 1, 28, 28)\n",
    "filter = torch.randn(1, 1, 3, 3)\n",
    "\n",
    "out_feat_F = F.conv2d()# code\n",
    "out_feat_F.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected :** `torch.Size([1, 1, 28, 28])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(1, 1, 28, 28)\n",
    "filter = torch.randn(1, 1, 2, 4)\n",
    "\n",
    "out_feat_F = F.conv2d()# code\n",
    "out_feat_F.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected :** `torch.Size([1, 1, 15, 14])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple convolution layer can be added one after the other but it can be useful to add a `Pooling` after some convolution layers.\n",
    "\n",
    "A limiting factor of convolutional layers is that they record the precise position of features (objects you're trying to detect) in the input. This means that small movements in the position of the feature in the input image will result in a different prediction. This can happen with re-cropping, rotation, shifting, and other minor changes to the input image\n",
    "\n",
    "A common approach to addressing this problem from signal processing is called down sampling. This is where a lower resolution version of an input signal is created that still contains the large or important structural elements, without the fine detail that may not be as useful to the task. This can be achieved by using `Pooling Layer`\n",
    "\n",
    "The most common pooling layer are `Max Pooling` and `Average Pooling`.\n",
    "\n",
    "They work similarly to simple convolution layers but instead of being multiplied by a kernel.\n",
    "\n",
    "Here is an example of bot pooling layer with a (2 x 2) filter, and a stride of 2.\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src=\"./.img/pooling.png\" width=\"400\" style=\"padding-left: 20px;\"/>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "`Max pooling` will take the pixel with the highest value in the kernel.\\\n",
    "`Average pooling` will take the average of each pixel in the kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution and Poling layer are implemented to highlight features in an image. These highlighted features must then go through fully connected layers to actually have an output in the end. After your convolution and pooling layer, you must flatten your data, to pass it into fully connected layer(s) to output 10 labels.\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "    <img src=\"./.img/full_model.png\" width=\"800\" style=\"padding-left: 20px;\"/>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "**Exercise :**\\\n",
    "With all of this knowledge, it's your turn to create a convolution model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # code\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # code\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "\n",
    "model = MyModel()\n",
    "loss_fonct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(EPOCH): #training\n",
    "    for batch in train_loader:\n",
    "        # code\n",
    "        pass\n",
    "\n",
    "total, correct = 0, 0\n",
    "for image, label in test_set: #testing\n",
    "    output = model.forward(image.reshape(1, 1, 28, 28))\n",
    "    if (output.argmax(dim=1).item() == label):\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Accuracy:\", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected :**\\\n",
    "`An accuracy above 85% is acceptable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratz\n",
    "\n",
    "Congratulations for having reached the end of this workshop!\\\n",
    "You have been able to create your own convolutional neural network using Pytorch.\n",
    "\n",
    "See you for the next topic!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
